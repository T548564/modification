% !TeX root = ../main.tex
% -*- coding: utf-8 -*-


\begin{zhaiyao}

%深度神经网络(Deep Neural Network, DNN)训练代价昂贵是导致模型知识产权保护问题逐渐被重视的原因。近年来，模型盗窃行为时常出现，不法分子对DNN模型非法复制，派生和发布的行为都严重侵犯了模型所有者的知识产权。许多研究者受到传统数字媒体水印的启发，从而设计模型水印和指纹用于验证模型所有权。然而，歧义性声明等攻击手段被用于破解模型水印和指纹，这对模型所有权验证工作造成了挑战。因此，需要设计一种知识产权保护方法能够解决上述问题。本文通过相关工作的调研，分析目前知识产权保护方法存在的难点与挑战，提出了一种基于近边界数据的模型所有权推断方法，主要工作如下：
%
%1）揭示了当前DNN模型所有权验证方案的脆弱性并确认了数据驱动推断模型所有权的有效性。模型水印和模型指纹的方法通常用是检测嵌入的水印或者通过特定触发集来验证所有权，这种方式在面对歧义攻击击等强攻击时，并不具备很强的鲁棒性。DNN模型通过数据集训练，所以不管是源模型还是其派生出来的模型，总会包含一定数据中的知识，本文确认了数据驱动推断模型所有权方法的有效性。
%
%2）提出了利用对抗性样本构造近边界数据以抵御模型窃取攻击。对抗性样本一般位于模型分类边界上并且相较于其他不相关的模型，对抗性样本可以更好的转移到从原始模型派生出的模型上。因此，本文利用对抗性样本构造了近边界数据来推断模型所有权，抵御模型窃取攻击。
%
%3）设计了基于DCGAN的近边界数据生成器和提出了一种损失函数用以微调源模型的目标分类边界，增加推断模型所有权的置信度。为了防止近边界数据被轻易复制，本文使用DCGAN的生成器生成我们私有的近边界数据。在此基础之上，重新设计了模型损失函数微调源模型，在保持DNN模型性能的情况下，以95\%以上的置信度成功推断模型所有权。
%
%4）本文在三个公开数据集上对本文提出的方法做了详细的测试，实验结果证明了基于近边界数据推断模型所有权的有效性和鲁棒性

深度神经网络(Deep Neural Network, DNN)训练代价昂贵，这是导致模型知识产权保护问题逐渐被重视的原因。近年来，模型盗窃行为频繁发生，攻击者非法复制、派生和发布DNN模型，严重侵犯了模型所有者的知识产权。因此，受到数字水印的启发，研究者提出了模型水印及指纹的方法，通过对模型提取水印或指纹进行匹配，从而验证模型所有权。然而，通过模型水印和指纹验证所有权具有较大的局限性，例如易被检测和清除。此外，攻击者还可以对模型发起歧义攻击，这是当前模型知识产权保护工作面临的重大挑战。为了解决上述问题，本文提出了一种新的思路，即推断模型所有权，代替以往基于模型水印和指纹验证模型所有权的方法。同时，本文提出了一种特殊的近边界数据，使用其对应的模型输出作为依据推断模型的所有权，解决伪造水印和指纹带来的歧义攻击问题，且不易被攻击者检测和清除。本文的主要工作如下：

1） 本文揭示了以往验证模型所有权方案的脆弱性和局限性，并确认了数据驱动推断模型所有权的有效性。本文提出了一种新颖的推断模型所有权思路。与过去工作中利用模型水印和指纹验证模型所有权相比，本文方法使用数据在对应模型上结果作为所有权推断依据，结果的可比性和唯一性可以有效避免歧义攻击。为了保证不影响原始数据集和模型，且作为依据的数据不被伪造，本文设计了一种特殊的近边界数据。实验验证了该数据的特性可以继承到目前主流的盗窃技术派生出的模型上，从而作为推断模型所有权的依据。

2）本文提出了基于近边界数据推断模型所有权的方法。该方法主要分为三个阶段：第一阶段通过改进的CW-$L_2$算法，从原始训练数据生成初始近边界数据；第二阶段设计了基于DCGAN的特征提取器，提取原始近边界数据特征后，生成新的、私有化的近边界数据；第三阶段设计了新的损失函数并微调源模型，使私有近边界数据更加靠近分类边界。最后提出使用假设检验的方法对比结果的差异，以95\%以上的置信度成功推断模型所有权。本文在三个开源数据集上进行了大量的实验，证明了本文方法在推断模型所有权时的有效性和鲁棒性。

%2） 本文提出了在对抗性样本的基础上生成初始的近边界数据。对抗性样本天然靠近分类模型分类边界的特征可以被利用，因此，本文对比了常见的对抗性样本生成算法，且实验结果表明CW-$L_2$算法效果最为显著。因此本文以该算法在源模型上的输出数据作为基础，选择其中与分类边界距离更近的部分数据作为初始近边界数据。
%
%3）本文设计了基于DCGAN的近边界特征提取器和一种损失函数用以微调源模型的目标分类边界。为了防止近边界数据被轻易复制，本文使用DCGAN的生成器生成我们私有的近边界数据。在此基础之上，重新设计了模型损失函数微调源模型，在保持DNN模型性能的情况下，以95\%以上的置信度成功推断模型所有权。

\end{zhaiyao}


\begin{guanjianci}
人工智能安全；知识产权保护；所有权推断；近边界数据；生成对抗网络
\end{guanjianci}



\begin{abstract}

Deep neural network (DNN) requires expensive training,
which is why the protection of model intellectual property
is becoming more critical. In recent years, model stealing has become more frequent, with attackers illegally copying, deriving, and releasing DNN models, severely infringing on the model owner's intellectual property. Therefore, inspired by digital watermarking, researchers have proposed methods of model watermarking and fingerprinting, which verify model ownership by matching extracted watermarks or fingerprints. However, ownership verification through model watermarking and fingerprinting has significant limitations, such as being easily detectable and removable. Additionally, attackers can launch ambiguous attacks on the model, which is a major challenge for current model intellectual property protection efforts. To address these issues, this thesis proposes a new approach, namely inferring model ownership, instead of relying on watermarking and fingerprinting methods to verify model ownership. Furthermore, this thesis proposes a special type of near-boundary data, using its corresponding model output as the basis for inferring model ownership, which solves the ambiguity attack caused by forged watermarks and fingerprints and is not easily detectable or removable by attackers. The main contributions of this thesis are as follows:

1)This thesis reveals the fragility and limitations of previous schemes for verifying model ownership and confirms the validity of data-driven inference of model ownership. This thesis proposes a novel approach for inferring model ownership. Compared to previous methods that rely on model watermarking and fingerprinting to verify model ownership, the approach in this thesis  uses the corresponding model output on the data as the basis for ownership inference. The comparability and uniqueness of the results can effectively avoid ambiguity attacks. To ensure that the original dataset and model are not affected and that the data used as the basis for inference cannot be forged, this thesis designs a special type of near-boundary data. The experiments verify that the properties of this data can be inherited to the models derived from the current mainstream theft techniques, and thus serve as the basis for inferring model ownership.

2)This thesis proposes a method for inferring model ownership based on near-boundary data. The method is mainly divided into three stages:   the first stage generates the initial near-boundary data from the original training data through the improved CW-$L_2$ algorithm; the second stage designs a DCGAN-based feature extractor to generate new, private near-boundary data after extracting the original near-boundary data features; the third stage designs a new loss function and fine-tunes the source model to make the private near-boundary data closer to the classification boundary. Finally, a hypothesis testing approach is proposed to compare the differences in the results and successfully infer model ownership with a confidence level of more than 95\%. This thesis conducts extensive experiments on three open-source datasets, demonstrating the effectiveness and robustness of this method for inferring model ownership.

\end{abstract}



\begin{keywords}
Artificial intelligence security; Intellectual property protection; Ownership inference; Near-boundary data; Generative adversarial network
\end{keywords} 